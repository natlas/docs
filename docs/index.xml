<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Natlas â€“ Documentation</title><link>/docs/</link><description>Recent content in Documentation on Natlas</description><generator>Hugo -- gohugo.io</generator><atom:link href="/docs/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Configuring Natlas Server</title><link>/docs/configuration/server/</link><pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate><guid>/docs/configuration/server/</guid><description>
&lt;p>There are a number of config options that you can specify in the application environment or in a file called &lt;code>.env&lt;/code> before initializing the database and launching the application. There are also a number of configuration options available for the server which change certain authentication-based behaviors as well as agent work configurations.&lt;/p>
&lt;h2 id="environment-config">Environment Config&lt;/h2>
&lt;p>Environment configs are loaded from the environment or a &lt;code>.env&lt;/code> file and require an application restart to change. Bind mounting a &lt;code>.env&lt;/code> file to &lt;code>/opt/natlas/natlas-server/.env&lt;/code> (rather than providing it as a docker env file) is encouraged so that passwords are not visible to the entire container.&lt;/p>
&lt;h3 id="core">Core&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Variable&lt;/th>
&lt;th>Default&lt;/th>
&lt;th>Explanation&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>SECRET_KEY&lt;/code>&lt;/td>
&lt;td>Randomly generated&lt;/td>
&lt;td>Used for CSRF tokens and sessions. You should generate a unique value for this in &lt;code>.env&lt;/code>, otherwise sessions will be invalidated whenever the app restarts.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>SERVER_NAME&lt;/code>&lt;/td>
&lt;td>&lt;code>None&lt;/code>&lt;/td>
&lt;td>This should be set to the domain and optional port that your service will be accessed on. Do &lt;strong>NOT&lt;/strong> include the scheme here. E.g. &lt;code>example.com&lt;/code> or &lt;code>10.0.0.15:5000&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>PREFERRED_URL_SCHEME&lt;/code>&lt;/td>
&lt;td>&lt;code>https&lt;/code>&lt;/td>
&lt;td>You can optionally set this value to &lt;code>http&lt;/code> if you&amp;rsquo;re not using ssl. This should be avoided for any production environments.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>CONSISTENT_SCAN_CYCLE&lt;/code>&lt;/td>
&lt;td>&lt;code>False&lt;/code>&lt;/td>
&lt;td>Setting this to &lt;code>True&lt;/code> will cause the random scan order to persist between scan cycles. This will produce more consistent deltas between an individual host being scanned. &lt;strong>Note&lt;/strong>: Changes to the scope will still change the scan order, resulting in one cycle of less consistent timing.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="data-storage">Data Storage&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Variable&lt;/th>
&lt;th>Default&lt;/th>
&lt;th>Explanation&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>DATA_DIR&lt;/code>&lt;/td>
&lt;td>&lt;code>/data&lt;/code>&lt;/td>
&lt;td>Path to store any data that should be persisted. Sqlite database, any log files, and media files all go in subdirectories of this directory.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>SQLALCHEMY_DATABASE_URI&lt;/code>&lt;/td>
&lt;td>&lt;code>sqlite:///$DATA_DIR/db/metadata.db&lt;/code>&lt;/td>
&lt;td>A &lt;a href="https://flask-sqlalchemy.palletsprojects.com/en/2.x/config/">SQLALCHEMY URI&lt;/a> that points to the database to store natlas metadata in. Supported types by natlas-server are: &lt;code>sqlite:&lt;/code>, &lt;code>mysql:&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>ELASTICSEARCH_URL&lt;/code>&lt;/td>
&lt;td>&lt;code>http://localhost:9200&lt;/code>&lt;/td>
&lt;td>A URL that points to the elasticsearch cluster to store natlas scan data in&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>MEDIA_DIRECTORY&lt;/code>&lt;/td>
&lt;td>&lt;code>$DATA_DIR/media/&lt;/code>&lt;/td>
&lt;td>If you want to store media (screenshots) in a larger mounted storage volume, set this value to an absolute path. If you change this value, be sure to copy the contents of the previous media directory to the new location, otherwise old media will not render.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="instrumentation">Instrumentation&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Variable&lt;/th>
&lt;th>Default&lt;/th>
&lt;th>Explanation&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>SENTRY_DSN&lt;/code>&lt;/td>
&lt;td>&lt;code>&amp;quot;&amp;quot;&lt;/code>&lt;/td>
&lt;td>Enables automatic reporting of all Flask exceptions to a &lt;a href="https://sentry.io/">Sentry.io instance&lt;/a>. Example: &lt;code>http://mytoken@mysentry.example.com/1&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>SENTRY_JS_DSN&lt;/code>&lt;/td>
&lt;td>&lt;code>&amp;quot;&amp;quot;&lt;/code>&lt;/td>
&lt;td>Enables automatic reporting of all JS errors to a &lt;a href="https://sentry.io/">Sentry.io instance&lt;/a>. This is separate from &lt;code>SENTRY_DSN&lt;/code> so you can report client-side errors separately from server-side.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>OPENCENSUS_ENABLE&lt;/code>&lt;/td>
&lt;td>&lt;code>false&lt;/code>&lt;/td>
&lt;td>Enables OpenCensus instrumentation to help identify performance bottlenecks.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>OPENCENSUS_SAMPLE_RATE&lt;/code>&lt;/td>
&lt;td>&lt;code>1.0&lt;/code>&lt;/td>
&lt;td>Specifies the percentage of requests that are traced with OpenCensus. A number from 0 to 1.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>OPENCENSUS_AGENT&lt;/code>&lt;/td>
&lt;td>&lt;code>127.0.0.1:55678&lt;/code>&lt;/td>
&lt;td>An OpenCensus agent or collector that this instance will emit traffic to.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="mail-settings">Mail Settings&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Variable&lt;/th>
&lt;th>Default&lt;/th>
&lt;th>Explanation&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>MAIL_SERVER&lt;/code>&lt;/td>
&lt;td>&lt;code>None&lt;/code>&lt;/td>
&lt;td>Mail server to use for invitations, registrations, and password resets&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>MAIL_PORT&lt;/code>&lt;/td>
&lt;td>&lt;code>587&lt;/code>&lt;/td>
&lt;td>Port that &lt;code>MAIL_SERVER&lt;/code> is listening on&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>MAIL_USE_TLS&lt;/code>&lt;/td>
&lt;td>&lt;code>True&lt;/code>&lt;/td>
&lt;td>Whether or not to connect to &lt;code>MAIL_SERVER&lt;/code> with STARTTLS&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>MAIL_USE_SSL&lt;/code>&lt;/td>
&lt;td>&lt;code>False&lt;/code>&lt;/td>
&lt;td>Whether or not to connect to &lt;code>MAIL_SERVER&lt;/code> with SSL (E.g. Port 465)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>MAIL_USERNAME&lt;/code>&lt;/td>
&lt;td>&lt;code>None&lt;/code>&lt;/td>
&lt;td>Username (if required) to connect to &lt;code>MAIL_SERVER&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>MAIL_PASSWORD&lt;/code>&lt;/td>
&lt;td>&lt;code>None&lt;/code>&lt;/td>
&lt;td>Password (if required) to connect to &lt;code>MAIL_SERVER&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>MAIL_FROM&lt;/code>&lt;/td>
&lt;td>&lt;code>None&lt;/code>&lt;/td>
&lt;td>Address to be used as the &amp;ldquo;From&amp;rdquo; address for outgoing mail. This is required if &lt;code>MAIL_SERVER&lt;/code> is set.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="development-settings">Development Settings&lt;/h3>
&lt;p>These settings are mostly only used for development purposes, and can have adverse effects if you modify them in your production environment.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Variable&lt;/th>
&lt;th>Default&lt;/th>
&lt;th>Explanation&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>FLASK_ENV&lt;/code>&lt;/td>
&lt;td>&lt;code>production&lt;/code>&lt;/td>
&lt;td>Used to tell flask which environment to run. Only change this if you are debugging or developing, and never leave your server running in anything but &lt;code>production&lt;/code>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>FLASK_APP&lt;/code>&lt;/td>
&lt;td>&lt;code>natlas-server.py&lt;/code>&lt;/td>
&lt;td>The file name that launches the flask application. This should not be changed as it allows commands like &lt;code>flask run&lt;/code>, &lt;code>flask db upgrade&lt;/code>, and &lt;code>flask shell&lt;/code> to run.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>NATLAS_VERSION_OVERRIDE&lt;/code>&lt;/td>
&lt;td>&lt;code>None&lt;/code>&lt;/td>
&lt;td>&lt;strong>Danger&lt;/strong>: This can be optionally set for development purposes to override the version string that natlas thinks it&amp;rsquo;s running. Doing this can have adverse affects and should only be done with caution. The only reason to really do this is if you&amp;rsquo;re developing changes to the way host data is stored and presented.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="example-env">Example ENV&lt;/h3>
&lt;p>The following is an example ENV file that assumes your elasticsearch cluster is accessible at &lt;code>172.17.0.2:9200&lt;/code> and that your mail server is accessible with authentication at &lt;code>172.17.0.4&lt;/code>. If you do not have a mail server, remove &lt;code>MAIL_&lt;/code> settings.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#8f5902;font-style:italic">#####&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># Flask Settings&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">#####&lt;/span>
&lt;span style="color:#000">SECRET_KEY&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>im-a-really-long-secret-please-dont-share-me
&lt;span style="color:#000">FLASK_ENV&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>production
&lt;span style="color:#8f5902;font-style:italic">#####&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># Data Stores&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">#####&lt;/span>
&lt;span style="color:#000">ELASTICSEARCH_URL&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>http://172.17.0.2:9200
&lt;span style="color:#8f5902;font-style:italic"># A mysql database via the mysqlclient driver&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">#SQLALCHEMY_DATABASE_URI=mysql://natlas:password@172.18.0.5/natlas&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># A sqlite database with a custom name vs the default metadata.db&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">#SQLALCHEMY_DATABASE_URI=sqlite:////data/db/test.db&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">#####&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># Mail settings&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">#####&lt;/span>
&lt;span style="color:#000">MAIL_SERVER&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>172.17.0.4
&lt;span style="color:#000">MAIL_USERNAME&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>dade.murphy
&lt;span style="color:#000">MAIL_PASSWORD&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>this-is-an-invalid-password
&lt;span style="color:#000">MAIL_FROM&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>noreply@example.com
&lt;span style="color:#8f5902;font-style:italic">#####&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># Natlas Specific Settings&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">#####&lt;/span>
&lt;span style="color:#000">CONSISTENT_SCAN_CYCLE&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>True
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="web-config">Web Config&lt;/h2>
&lt;p>Web configs are loaded from the SQL database and changeable from the web interface without requiring an application restart.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Variable&lt;/th>
&lt;th>Default&lt;/th>
&lt;th>Explanation&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>LOGIN_REQUIRED&lt;/code>&lt;/td>
&lt;td>&lt;code>True&lt;/code>&lt;/td>
&lt;td>Require login to browse results&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>REGISTER_ALLOWED&lt;/code>&lt;/td>
&lt;td>&lt;code>False&lt;/code>&lt;/td>
&lt;td>Permit open registration for new users&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>AGENT_AUTHENTICATION&lt;/code>&lt;/td>
&lt;td>&lt;code>True&lt;/code>&lt;/td>
&lt;td>Optionally require agents to authenticate before being allowed to get or submit work&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>CUSTOM_BRAND&lt;/code>&lt;/td>
&lt;td>&lt;code>&amp;quot;&amp;quot;&lt;/code>&lt;/td>
&lt;td>Custom branding for the navigation bar to help distinguish different natlas installations from one another&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item><item><title>Docs: Managing Users</title><link>/docs/tasks/server-administration/managing-users/</link><pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate><guid>/docs/tasks/server-administration/managing-users/</guid><description>
&lt;h2 id="adding-your-first-user">Adding Your First User&lt;/h2>
&lt;p>Your first user is the most important for your Natlas server. You&amp;rsquo;ll want to create yourself an admin account so that you can manage your deployment. The first user must be &lt;a href="#inviting-by-cli">invited via cli&lt;/a>. All container references for CLI assume that your container is named &lt;code>natlas_server&lt;/code>.&lt;/p>
&lt;h2 id="inviting-new-users">Inviting New Users&lt;/h2>
&lt;h3 id="inviting-by-cli">Inviting by CLI&lt;/h3>
&lt;p>Inviting via CLI is pretty easy but has one small quirk - you have to ensure the &lt;code>SERVER_NAME&lt;/code> environment variable is set for your server so that invitation links can be generated correctly. If it&amp;rsquo;s not set, the command will fail.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ docker &lt;span style="color:#204a87">exec&lt;/span> -e &lt;span style="color:#000">SERVER_NAME&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>example.com -it natlas_server flask user new --admin
Accept invitation: http://example.com/auth/invite?token&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>this-is-an-invalid-example-token
&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can then take this invitation into your browser and create your account.&lt;/p>
&lt;h3 id="inviting-by-web">Inviting by Web&lt;/h3>
&lt;p>If you already have an account, inviting a new user via the web interface is also very easy at &lt;code>/admin/users&lt;/code>. Simply add their email address in the text box and hit Invite User.&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/y8a1AD4.png" alt="Invite Users">&lt;/p>
&lt;h2 id="promoting-a-user">Promoting A User&lt;/h2>
&lt;p>Promoting a user means to change their role from a normal user to an admin.&lt;/p>
&lt;h3 id="promoting-by-cli">Promoting by CLI&lt;/h3>
&lt;p>Promoting a user via CLI requires two things: Access to the docker container and the email address of the user you want to promote.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">$ docker &lt;span style="color:#204a87">exec&lt;/span> -it natlas_server flask user role --promote user@example.com
user@example.com is now an admin
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="promoting-by-web">Promoting by Web&lt;/h3>
&lt;p>Promoting a user on the web panel is super easy as long as you already have an admin account. Simply find their email address in the &lt;code>/admin/users&lt;/code> page and click the Promote button.&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/1HRYXUW.png" alt="Promoting a user">&lt;/p></description></item><item><title>Docs: Configuring Natlas Agent</title><link>/docs/configuration/agent/</link><pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate><guid>/docs/configuration/agent/</guid><description>
&lt;h2 id="environment-config">Environment Config&lt;/h2>
&lt;p>All agent configurations are controlled via environment variables. To make modifications to your agent, you can modify environment variables to match your specifications. These options should be placed in a file called &lt;code>.env&lt;/code> that gets mounted into your container in &lt;code>/opt/natlas/natlas-agent/.env&lt;/code>.&lt;/p>
&lt;h3 id="server-communication">Server Communication&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Variable&lt;/th>
&lt;th>Default&lt;/th>
&lt;th>Explanation&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>NATLAS_SERVER_ADDRESS&lt;/code>&lt;/td>
&lt;td>&lt;code>http://127.0.0.1:5000&lt;/code>&lt;/td>
&lt;td>The server to get work from and submit work to.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>NATLAS_IGNORE_SSL_WARN&lt;/code>&lt;/td>
&lt;td>&lt;code>False&lt;/code>&lt;/td>
&lt;td>Ignore certificate errors when connecting to &lt;code>NATLAS_SERVER_ADDRESS&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>NATLAS_REQUEST_TIMEOUT&lt;/code>&lt;/td>
&lt;td>&lt;code>15&lt;/code> (seconds)&lt;/td>
&lt;td>Time to wait for the server to respond&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>NATLAS_BACKOFF_MAX&lt;/code>&lt;/td>
&lt;td>&lt;code>300&lt;/code> (seconds)&lt;/td>
&lt;td>Maximum time for exponential backoff after failed requests&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>NATLAS_BACKOFF_BASE&lt;/code>&lt;/td>
&lt;td>&lt;code>1&lt;/code> (second)&lt;/td>
&lt;td>Incremental time for exponential backoff after failed requests&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>NATLAS_MAX_RETRIES&lt;/code>&lt;/td>
&lt;td>&lt;code>10&lt;/code>&lt;/td>
&lt;td>Number of times to retry a request to the server before giving up&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="agent-authentication">Agent Authentication&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Variable&lt;/th>
&lt;th>Default&lt;/th>
&lt;th>Explanation&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>NATLAS_AGENT_ID&lt;/code>&lt;/td>
&lt;td>&lt;code>None&lt;/code>&lt;/td>
&lt;td>ID string that identifies scans made by this host, required for agent authentication, optional if agent authentication is not required. Get this from your &lt;code>/user/&lt;/code> page on the Natlas server if agent authentication is enabled.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>NATLAS_AGENT_TOKEN&lt;/code>&lt;/td>
&lt;td>&lt;code>None&lt;/code>&lt;/td>
&lt;td>Secret token needed when agent authentication is required. Generate this with the ID on the &lt;code>/user/&lt;/code> page on the Natlas server.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="agent-behavior">Agent Behavior&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Variable&lt;/th>
&lt;th>Default&lt;/th>
&lt;th>Explanation&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>NATLAS_MAX_THREADS&lt;/code>&lt;/td>
&lt;td>&lt;code>3&lt;/code>&lt;/td>
&lt;td>Maximum number of concurrent scanning threads&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>NATLAS_SCAN_LOCAL&lt;/code>&lt;/td>
&lt;td>&lt;code>False&lt;/code>&lt;/td>
&lt;td>Don&amp;rsquo;t scan local addresses&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="instrumentation">Instrumentation&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Variable&lt;/th>
&lt;th>Default&lt;/th>
&lt;th>Explanation&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>SENTRY_DSN&lt;/code>&lt;/td>
&lt;td>&lt;code>&amp;quot;&amp;quot;&lt;/code>&lt;/td>
&lt;td>If set, enables automatic reporting of all exceptions to a &lt;a href="https://sentry.io/">Sentry.io instance&lt;/a>. Example: &lt;code>http://mytoken@mysentry.example.com/1&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>SENTRY_ENVIRONMENT&lt;/code>&lt;/td>
&lt;td>&lt;code>None&lt;/code>&lt;/td>
&lt;td>Specifies the value to provided for the &lt;code>environment&lt;/code> tag in Sentry. Use it to differentiate between different stages or stacks. e.g. &lt;code>Beta&lt;/code> or &lt;code>Prod&lt;/code>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="development-settings">Development Settings&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Variable&lt;/th>
&lt;th>Default&lt;/th>
&lt;th>Explanation&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>NATLAS_SAVE_FAILS&lt;/code>&lt;/td>
&lt;td>&lt;code>False&lt;/code>&lt;/td>
&lt;td>Optionally save scan data that fails to upload for whatever reason. If you enable this, you will also want to mount a persistent data store at &lt;code>/data&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>NATLAS_VERSION_OVERRIDE&lt;/code>&lt;/td>
&lt;td>&lt;code>None&lt;/code>&lt;/td>
&lt;td>&lt;strong>Danger&lt;/strong>: This can be optionally set for development purposes to override the version string that natlas thinks it&amp;rsquo;s running. Doing this can have adverse affects and should only be done with caution. The only reason to really do this is if you&amp;rsquo;re developing changes to the way host data is stored and presented.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="example-env">Example ENV&lt;/h2>
&lt;p>At minimum, you&amp;rsquo;ll want to define these configuration options. Get &lt;code>NATLAS_AGENT_ID&lt;/code> and &lt;code>NATLAS_AGENT_TOKEN&lt;/code> from the &lt;code>/user/&lt;/code> profile page of your Natlas server.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#000">NATLAS_SERVER_ADDRESS&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>https://natlas.io
&lt;span style="color:#000">NATLAS_MAX_THREADS&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">25&lt;/span>
&lt;span style="color:#000">NATLAS_AGENT_ID&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>this-is-example-id
&lt;span style="color:#000">NATLAS_AGENT_TOKEN&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>this-is-obviously-an-example-token
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: Managing Scope</title><link>/docs/tasks/server-administration/managing-scope/</link><pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate><guid>/docs/tasks/server-administration/managing-scope/</guid><description>
&lt;h2 id="importing-scope">Importing Scope&lt;/h2>
&lt;p>Before your Natlas deployment can do anything useful, you&amp;rsquo;ll need to import some scope addresses for your agents to scan. Natlas provides two paths for doing this: CLI and Web. The CLI demos in this documentation assumes that your natlas server container is named &lt;code>natlas_server&lt;/code>.&lt;/p>
&lt;h3 id="the-scope-file">The Scope File&lt;/h3>
&lt;p>Your scope file will be a csv file with each row representing one CIDR network, optionally followed by a list of comma-separated tags to describe that CIDR network. E.g.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-text" data-lang="text">192.168.0.0/16,home,class-b
172.16.0.0/16,vpn,class-b
10.0.0.0/8,overlay,class-a,super cool network
192.168.0.100/32,pihole
192.168.100.1/32,modem
192.168.0.1/32,router
&lt;/code>&lt;/pre>&lt;/div>&lt;p>An observant reader will notice that the last 3 addresses all fall within the range of the first network. This is fine, more specific addresses will be tracked individually so that you can tag them with whatever you want. Just note that if you later choose to exclude the &lt;code>192.168.0.0/16&lt;/code> network, all addresses that fall inside that range will also be excluded, regardless if they are also individual items in the rest of the scope.&lt;/p>
&lt;h3 id="importing-by-cli">Importing by CLI&lt;/h3>
&lt;p>Importing via CLI is pretty straight forward but requires putting your scope file into the persistent mounted directory. Since the server requires this directory to store media files already, it shouldn&amp;rsquo;t be a big deal to drop your bootstrap scope into that directory. The data will be available in &lt;code>/data&lt;/code> inside the container.&lt;/p>
&lt;p>We put our scope file into our persistent storage directory and then we can import it with flask like so:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">docker &lt;span style="color:#204a87">exec&lt;/span> -it natlas_server flask scope import --verbose /data/myscopefile.txt &amp;gt; /data/import_results.json
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Remember, the &lt;code>/data/myscopefile.txt&lt;/code> and &lt;code>/data/import_results.json&lt;/code> are relative to the docker container, not to the host filesystem.&lt;/p>
&lt;h3 id="importing-by-web">Importing by Web&lt;/h3>
&lt;p>Maybe manipulating the flask application through the docker layer is too verbose and you don&amp;rsquo;t want to do it. That&amp;rsquo;s fine and dandy, Natlas provides a web interface for admin users to import scope items individually or in bulk at the &lt;code>/admin/scope&lt;/code> url. The bulk import works the same way as the file import on CLI, except you paste the contents of the file rather than uploading the file itself.&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/KWByFj5.png" alt="Scope Management Panel">&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/ODGWNVB.png" alt="Scope Import">&lt;/p>
&lt;h2 id="exporting-scope">Exporting Scope&lt;/h2>
&lt;h3 id="exporting-by-cli">Exporting by CLI&lt;/h3>
&lt;p>The CLI claims to support exporting scope, however there is currently a bug (&lt;a href="https://github.com/natlas/natlas/issues/426">#246&lt;/a>) that prevents this from working correctly when your scope items are tagged.&lt;/p>
&lt;h3 id="exporting-by-web">Exporting by Web&lt;/h3>
&lt;p>As you can see above in the scope management panel, there&amp;rsquo;s a simple export button. You can also reach this directly by visiting &lt;code>/admin/export/scope&lt;/code> while logged in as an Admin. This produces a simple line-separated list of in-scope networks.&lt;/p>
&lt;h2 id="disabling-scope">Disabling Scope&lt;/h2>
&lt;p>Disabling scope is a way to remove specific addresses or subnets from being scanned. This can be important if you&amp;rsquo;re scanning things that are likely to tip over when being touched by nmap, or things that are deemed &amp;ldquo;too risky to scan.&amp;rdquo; You can easily add new network blocks to the exclusion list, or simply move existing network blocks.&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/o7NGFHa.png" alt="Disabling existing scope">&lt;/p></description></item><item><title>Docs: Searching Natlas</title><link>/docs/tasks/searching-natlas/</link><pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate><guid>/docs/tasks/searching-natlas/</guid><description>
&lt;p>Natlas search is powered by &lt;a href="https://www.elastic.co/">Elasticsearch&lt;/a>, and the syntax that the search box uses is currently equivalent to an Elastic &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html">Query string query&lt;/a>. For a deeper understanding of the query string syntax, please consult that page. A key thing to remember when building queries is that, by default, more search terms results in a narrower result set. Each additional search term serves to further reduce the result set.&lt;/p>
&lt;p>The Natlas elastic mapping currently makes a lot of things available to you to search, but it may be less than intuitive or unnecessarily verbose because there are no abstractions or shortcuts for common queries. So this page should help you to build more effective queries.&lt;/p>
&lt;p>If you choose not to specify any fields to query for, it will default to searching the &lt;code>nmap_data&lt;/code> field, which is roughly equivalent to grepping through your &lt;code>scan.nmap&lt;/code> files.&lt;/p>
&lt;h2 id="basic-syntax">Basic Syntax&lt;/h2>
&lt;p>This section will not go into depth about the query string syntax, but will cover some of the most common operators.&lt;/p>
&lt;p>Natlas supports &lt;code>AND&lt;/code>, &lt;code>OR&lt;/code>, and &lt;code>NOT&lt;/code> for combining queries. The default operator for Natlas is &lt;code>AND&lt;/code> when multiple search terms are present, (separated by a space). This is important to remember, as the default for Elastic is typically &lt;code>OR&lt;/code>. If you&amp;rsquo;d like to use &lt;code>OR&lt;/code>, you can do so like so: &lt;code>ports.port:80 OR ports.port:443&lt;/code>, which returns hosts that have port 80 or port 443 open.&lt;/p>
&lt;p>&lt;code>NOT&lt;/code> can also be shortened to &lt;code>!&lt;/code>, e.g. &lt;code>!tags:&amp;quot;Corpnet-A&amp;quot;&lt;/code> to return only results that are not tagged with &amp;ldquo;Corpnet-A&amp;rdquo;.&lt;/p>
&lt;p>Natlas also supports wildcard operators when searching text fields, such as &lt;code>hostname:*.example.com&lt;/code> to match all subdomains of example.com, or &lt;code>hostname:example.???&lt;/code> to find all example.tld domains that have a 3 letter tld.&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;p>Metadata terms are those that are related to the Natlas scan but are not directly related to the acquired scan data.&lt;/p>
&lt;h3 id="scan-information">Scan Information&lt;/h3>
&lt;h4 id="scan_reason">scan_reason&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>scan_reason:manual&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> scan_reason is used to differentiate between automatic scanning, manually submitted scans, and user-requested rescans. The valid options for this are &lt;code>manual&lt;/code>, &lt;code>automatic&lt;/code>, and &lt;code>requested&lt;/code>.&lt;/p>
&lt;h4 id="tags">tags&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>tags:Digital Ocean&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> tags are applied to scope ranges to automatically group different groups of IP addresses together. These are completely configurable per deployment.&lt;/p>
&lt;h4 id="scan_id">scan_id&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>scan_id:b8befe174067010b6182c3ca28baf095&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> scan_id is an automatically generated token that uniquely identifies a scan. This is particularly useful if you want to share specific scans with someone.&lt;/p>
&lt;h4 id="ip">ip&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ip:10.0.0.0/8&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> ip is the IP address targeted by the scan, and supports CIDR notation so that you can search for entire CIDR ranges at a time. The example shows all scans from the &lt;code>10.0.0.0/8&lt;/code> network.&lt;/p>
&lt;h4 id="hostname">hostname&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>hostname:*.example.com&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> hostname is determined by nmap as the rDNS (PTR record) value for a given IP address. The example query shows all scans that have a PTR record for a subdomain of example.com&lt;/p>
&lt;h3 id="automatic-queries">Automatic Queries&lt;/h3>
&lt;p>These terms are inherent to all search results by default and do not need to be explicitly defined:&lt;/p>
&lt;h4 id="port_count">port_count&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>port_count:&amp;gt;0&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> port_count is calculated based on the number of open ports that a scan reports. The example query shows all scans that have more than 0 ports open.&lt;/p>
&lt;h4 id="is_up">is_up&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>is_up:True&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> is_up is reported by nmap for whether or not it determined the host was up. This defaults to True for search queries, because looking at hosts that we don&amp;rsquo;t have data for isn&amp;rsquo;t very interesting.&lt;/p>
&lt;h3 id="timing">Timing&lt;/h3>
&lt;p>These search operators all pertain to date related fields that are inherent to the Natlas scan documents. These all support operators like &lt;code>&amp;gt;&lt;/code>, &lt;code>&amp;lt;&lt;/code>, &lt;code>&amp;lt;=&lt;/code> and &lt;code>&amp;gt;=&lt;/code> to do simple comparisons comparisons.&lt;/p>
&lt;h4 id="ctime">ctime&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ctime:&amp;gt;=2020-01-01&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> ctime is the creation time of the scan document, which means when the server inserts it into Elastic. The example query shows all scans that were inserted on or after January 1st, 2020.&lt;/p>
&lt;h4 id="scan_start">scan_start&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>scan_start:2020-01-05&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> scan_start is provided by the agent and tells us when the agent starts doing its work. The example query shows all scans that started (but not necessarily finished) on January 5th, 2020.&lt;/p>
&lt;h4 id="scan_stop">scan_stop&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>scan_stop:2020-01-05&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> scan_stop is provided by the agent and tells us when the agent stopped doing it&amp;rsquo;s work. The example query shows all scans that stopped (but not necessarily started) on January 5th, 2020.&lt;/p>
&lt;h4 id="elapsed">elapsed&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>elapsed:&amp;gt;60&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> elapsed is calculated based on scan_start and scan_stop and tells us how long the agent spent working on a particular job. The example query shows all scans that took longer than 60 seconds to perform.&lt;/p>
&lt;h3 id="agent">Agent&lt;/h3>
&lt;p>These search terms pertain to the agent that performed the work.&lt;/p>
&lt;h4 id="agent-1">agent&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>agent:44040760a19f5dc6&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> agent is the identification token of the agent that performed the work. If no token is present, this value will be &lt;code>anonymous&lt;/code>.&lt;/p>
&lt;h4 id="agent_version">agent_version&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>agent_version:0.6.11&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> agent_version is the configured &lt;code>NATLAS_VERSION&lt;/code> of the agent that reported the work. In &lt;code>0.6.x&lt;/code> this is used to determine how to render the scan data.&lt;/p>
&lt;h2 id="screenshots">Screenshots&lt;/h2>
&lt;p>These search terms all focus on finding screenshots that meet specific criteria. You&amp;rsquo;ll notice that all of these are prepended with &lt;code>screenshots.&lt;/code>, which is how you specify the specific field in the document that you want to scan when it isn&amp;rsquo;t at the top level of the document. This will be a recurring theme for the rest of this documentation.&lt;/p>
&lt;h3 id="screenshotshost">screenshots.host&lt;/h3>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>screenshots.host:*.example.com&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Returns scan results that have a screenshot for the provided host. The host may be a DNS name or an IP address. The example query returns scan results for all subdomains of example.com (as determined by their PTR record) that have a screenshot.&lt;/p>
&lt;h3 id="screenshotsport">screenshots.port&lt;/h3>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>screenshots.port:8089&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Returns scan results that have a screenshot for the specified port. The example query returns all scans that have a screenshot for port 8089.&lt;/p>
&lt;h3 id="screenshotsservice">screenshots.service&lt;/h3>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>screenshots.service:VNC&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Returns scan results that have a screenshot for the specified service. Note that these values are case sensitive and must be uppercase at this time. The currently supported services are &lt;code>HTTP&lt;/code>, &lt;code>HTTPS&lt;/code>, and &lt;code>VNC&lt;/code>.&lt;/p>
&lt;h3 id="screenshotshash">screenshots.hash&lt;/h3>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>screenshots.hash:&amp;lt;sha256&amp;gt;&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Returns scan results that have a screenshot with the specified hash. This is helpful for finding all hosts that have an identical service running. Note that this is an exact match, not a fuzzy hash.&lt;/p>
&lt;h3 id="screenshotsthumb_hash">screenshots.thumb_hash&lt;/h3>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>screenshots.thumb_hash:&amp;lt;sha256&amp;gt;&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Returns scan results that have a screenshot whose thumbnail matches the specified hash. This is mostly equivalent to &lt;code>screenshots.hash&lt;/code> except it searches thumbnails instead of full size images.&lt;/p>
&lt;h2 id="ports">Ports&lt;/h2>
&lt;p>Searching port data is probably the most important thing you&amp;rsquo;ll want to do with Natlas, but it can also be the most complex. Values in the ports structure are sometimes deeply nested and complicated to build queries for.&lt;/p>
&lt;h3 id="portsid">ports.id&lt;/h3>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.id:tcp.80&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> This is the port id from nmap, which is a combination of the protocol and the port number. The example query searches for ports that have tcp port 80 open.&lt;/p>
&lt;h3 id="portsport">ports.port&lt;/h3>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.port:80&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> This is the port number from nmap, without regard for the protocol. The example query searches for all hosts that have port 80 open, regardless of tcp or udp.&lt;/p>
&lt;h3 id="portsprotocol">ports.protocol&lt;/h3>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.protocol:tcp&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> This is the port protocol from nmap. The example query searches for all hosts that have a tcp port open, regardless of what number it is. Largely, this query is probably not going to be very helpful since all results will probably have a tcp port open.&lt;/p>
&lt;h3 id="portsstate">ports.state&lt;/h3>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.state:open&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> This is the port state from nmap. The example query searches for all hosts that have a port open. Again, probably not especially helpful.&lt;/p>
&lt;h3 id="portsreason">ports.reason&lt;/h3>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.reason:syn-ack&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> This is the reason the port is included by nmap. &lt;code>syn-ack&lt;/code> is probably going to be the most common, and therefore the least useful.&lt;/p>
&lt;h3 id="portsbanner">ports.banner&lt;/h3>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.banner:Apache&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> This searches the banner string produced by nmap. The example shows all hosts with an Apache service reported in the banner grab.&lt;/p>
&lt;h3 id="service">Service&lt;/h3>
&lt;p>Remember in the last section how I said that port data is complex and sometimes deeply nested, well, welcome to the first next layer. This section pertains to information about the service running on a port. Basically what this does is provides a more nuanced approach to searching the results of nmap&amp;rsquo;s service fingerprinting, rather than searching the text field &lt;code>ports.banner&lt;/code> from the previous section.&lt;/p>
&lt;h4 id="portsservicename">ports.service.name&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.service.name:http&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> This is the service name that nmap determines from the port. With service fingerprinting enabled, this may originate from the fingerprints. Otherwise it will fall back to what&amp;rsquo;s in the provided services database. The example will find hosts that have at least one http service running.&lt;/p>
&lt;h4 id="portsserviceproduct">ports.service.product&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.service.product:Minecraft&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> This is the product that nmap determines from the service fingerprint. The example query will find instances of Minecraft running (notice that this is case sensitive).&lt;/p>
&lt;h4 id="portsserviceversion">ports.service.version&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.service.version:1.16.1&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> This is the product version that nmap determines from the service fingerprint. The example query will find anything with a version string of &lt;code>1.16.1&lt;/code>&lt;/p>
&lt;h4 id="portsserviceostype">ports.service.ostype&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.service.ostype:Linux&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> This is the OS type determined by nmap. The example query will find anything that is determined to be Linux.&lt;/p>
&lt;h4 id="portsserviceconf">ports.service.conf&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.service.conf:&amp;gt;9&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> This is the confidence level of nmap that the service it identified is actually that service. This is an integer value between 0 and 10, with 10 being the most confident about the accuracy of the reported service.&lt;/p>
&lt;h4 id="portsservicecpelist">ports.service.cpelist&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.service.cpelist:&amp;quot;cpe:/a:apache:http_server:2.4.29&amp;quot;&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> This is the &lt;a href="https://nvd.nist.gov/products/cpe">CPE&lt;/a> identifier for the identified service. The example shows us Apache http servers running version 2.4.29.&lt;/p>
&lt;h4 id="portsservicemethod">ports.service.method&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.service.method:probed&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> This is the method that nmap used to determine what the service was. &lt;code>probed&lt;/code> means that it was the result of the probes, &lt;code>table&lt;/code> means that it was grabbed from the services database.&lt;/p>
&lt;h4 id="portsserviceextrainfo">ports.service.extrainfo&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.service.extrainfo:&amp;quot;ubuntu&amp;quot;&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Extraneous information retrieved by the nmap service fingerprint that doesn&amp;rsquo;t fit directly into one of the other categories. The example looks for instances of ubuntu, indicating that it&amp;rsquo;s likely to be an Ubuntu linux server.&lt;/p>
&lt;h4 id="portsservicetunnel">ports.service.tunnel&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.service.tunnel:ssl&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Whether or not the host has a port that uses a tunnel, such as ssl.&lt;/p>
&lt;h3 id="scripts">Scripts&lt;/h3>
&lt;p>Everything in this section involves searching the output of the nmap scripting engine. Most script outputs are stored as text blobs that you&amp;rsquo;ll have to search through.&lt;/p>
&lt;h4 id="portsscriptsid">ports.scripts.id&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.scripts.id:http-git&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Look for hosts that have ports open where a specific script was executed. The example will look for hosts that have results for the &lt;code>http-git&lt;/code> script (looking for &lt;code>/.git&lt;/code> folders in http web roots)&lt;/p>
&lt;h4 id="portsscriptsoutput">ports.scripts.output&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.scripts.output:&amp;quot;github.com&amp;quot;&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Perform string searches on the output of scripts. The example will look for script output where &amp;ldquo;github.com&amp;rdquo; appears, such as in the previous &lt;code>http-git&lt;/code> example.&lt;/p>
&lt;h3 id="ssl">SSL&lt;/h3>
&lt;p>SSL Data is collected by the nmap scripting engine and is also available with the &lt;code>ports.scripts.id:ssl-cert&lt;/code> query, however these certificates are important enough, and complicated enough, to be parsed out into structured fields. But alas, SSL data is the most deeply nested of all of the search terms, so prepare yourselves.&lt;/p>
&lt;h4 id="portssslmd5">ports.ssl.md5&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.ssl.md5:da979cf70ae708ffb1d8a247a0cf5acb&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Looks for hosts that have an ssl certificate with a specific md5 hash.&lt;/p>
&lt;h4 id="portssslsha1">ports.ssl.sha1&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.ssl.sha1:28cfccaf54b309b6d7c58b400ce8262f3121a495&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Looks for hosts that have an ssl certificate with a specific sha1 hash.&lt;/p>
&lt;h4 id="portssslnotafter">ports.ssl.notAfter&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.ssl.notAfter:&amp;lt;2020-08-16&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Look for hosts that have ssl certificates with a particular expiration date. The example looks for certificates with an expiration date prior to August 16th, 2020.&lt;/p>
&lt;h4 id="portssslnotbefore">ports.ssl.notBefore&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.ssl.notBefore:&amp;gt;2020-01-01&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Look for hosts that have ssl certificates with a particular notBefore validity date. The example looks for certificates that were issued after January 1st, 2020.&lt;/p>
&lt;h4 id="portssslsig_alg">ports.ssl.sig_alg&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.ssl.sig_alg:sha256WithRSAEncryption&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Look for hosts that use a specific signature algorithm for the ssl certificate. The example looks for signature algorithm &lt;code>sha256WithRSAEncryption&lt;/code>.&lt;/p>
&lt;h4 id="portssslpubkeybits">ports.ssl.pubkey.bits&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.ssl.pubkey.bits:&amp;lt;2048&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Look for hosts that have a pubkey with a particular size. The example looks for hosts that have pubkeys that are less than a 2048-bit key.&lt;/p>
&lt;h4 id="portssslpubkeytype">ports.ssl.pubkey.type&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.ssl.pubkey.type:ec&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Look for hosts that use an ssl pubkey of a specific type. The example looks for ssl pubkeys using Elliptic Curve (ec).&lt;/p>
&lt;h4 id="portssslissuercommonname">ports.ssl.issuer.commonName&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.ssl.issuer.commonName:&amp;quot;Let's Encrypt Authority X3&amp;quot;&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Look for hosts that have a certificate issued by a specific issuer. The example looks for certificates issued by Let&amp;rsquo;s Encrypt&amp;rsquo;s Authority X3 issuer.&lt;/p>
&lt;h4 id="portssslissuercountryname">ports.ssl.issuer.countryName&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.ssl.issuer.countryName:us&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Look for hosts that have a certificate issued by an issuer in a specific country. The example looks for certificates issued by an issuer in the United States.&lt;/p>
&lt;h4 id="portssslissuerorganizationname">ports.ssl.issuer.organizationName&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.ssl.issuer.organizationName:&amp;quot;Let's Encrypt&amp;quot;&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Look for hosts that have a certificate issued by a specific organization. The example looks for certificates issued by Let&amp;rsquo;s Encrypt.&lt;/p>
&lt;h4 id="portssslsubjectcommonname">ports.ssl.subject.commonName&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.ssl.subject.commonName:*.example.com&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Look for hosts that have a certificate issued to a specific subject. The example looks for certificates issued to subdomains of example.com.&lt;/p>
&lt;h4 id="portssslsubjectaltnames">ports.ssl.subject.altNames&lt;/h4>
&lt;p>&lt;strong>Example:&lt;/strong> &lt;code>ports.ssl.subject.altNames:*.example.com&lt;/code>&lt;/p>
&lt;p>&lt;strong>Description:&lt;/strong> Look for hosts that have a certificate with Subject Alternate Names for a specific subject. The example looks for certificates issued that are also valid for subdomains of example.com.&lt;/p></description></item><item><title>Docs: Managing Agents</title><link>/docs/tasks/server-administration/managing-agents/</link><pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate><guid>/docs/tasks/server-administration/managing-agents/</guid><description>
&lt;h2 id="configuring-port-coverage">Configuring Port Coverage&lt;/h2>
&lt;p>Port coverage is configured via a server side &lt;a href="https://nmap.org/book/nmap-services.html">nmap-services&lt;/a> file, which is used by nmap to know what ports to scan. Natlas maintains it&amp;rsquo;s &lt;a href="https://github.com/natlas/natlas/blob/main/natlas-server/defaults/natlas-services">own version of this file&lt;/a>, which is shipped with the application. We use it to add new common or interesting ports that the default nmap-services doesn&amp;rsquo;t cover. You&amp;rsquo;re welcome to add or remove as many ports as you want from this file.&lt;/p>
&lt;p>To access this on your server, visit the &lt;code>/admin/services&lt;/code> endpoint while logged in with an admin account. It&amp;rsquo;ll look something like this:&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/I3UdVfJ.png" alt="Natlas Services Page">&lt;/p>
&lt;p>From here, you can add individual new services via the form, or you can upload a new services file to completely replace the current one.&lt;/p>
&lt;h2 id="configuring-scans">Configuring Scans&lt;/h2>
&lt;p>Everything about scans, except what ports are covered, can be found in the &lt;code>/admin/agents&lt;/code> url. This includes what nmap settings to use as well as whether or not you want them to collect screenshots of web services or vnc services.&lt;/p>
&lt;p>&lt;img src="https://i.imgur.com/9G7UeZp.png" alt="Agent configuration page">&lt;/p>
&lt;h3 id="supported-nmap-options">Supported Nmap Options&lt;/h3>
&lt;p>Natlas doesn&amp;rsquo;t support raw nmap command editing, because it makes a goal to not allow arbitrary execution on the agents. As such, we currently only support a limited subset of nmap options. They are as follows:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://nmap.org/book/man-version-detection.html">Version Detection&lt;/a> (-sV)&lt;/li>
&lt;li>&lt;a href="https://nmap.org/book/man-os-detection.html">OS Detection&lt;/a> (-O)&lt;/li>
&lt;li>&lt;a href="https://nmap.org/book/man-os-detection.html">Limit OS Scan&lt;/a> (&amp;ndash;osscan-limit)&lt;/li>
&lt;li>&lt;a href="https://nmap.org/book/nse-usage.html">Enable Scripting Engine&lt;/a> (&amp;ndash;script)&lt;/li>
&lt;li>&lt;a href="https://nmap.org/book/man-output.html">Report Open Ports Only&lt;/a> (&amp;ndash;open)&lt;/li>
&lt;li>&lt;a href="https://nmap.org/book/man-host-discovery.html">Bypass Host Discovery&lt;/a> (-Pn)&lt;/li>
&lt;li>&lt;a href="https://nmap.org/book/scan-methods-udp-scan.html">Scan TCP+UDP&lt;/a> (-sUS) &lt;strong>Note:&lt;/strong> This requires your services file to have udp ports in it.&lt;/li>
&lt;/ul>
&lt;h3 id="nmap-scripts">Nmap Scripts&lt;/h3>
&lt;p>The list of scripts to scan is stored separately so that you can easily add and remove scripts. This field allows individual script names as well as script categories. Check out the &lt;a href="https://nmap.org/book/man-nse.html">nmap documentation&lt;/a> for more information about this, or checkout the &lt;a href="https://nmap.org/nsedoc/lib/nmap.html">NSE Library&lt;/a> for the list of scripts that are shipped with nmap.&lt;/p>
&lt;p>At this time, Natlas does not support sending custom scripts to the agents due to the security design of the agents. Custom NSE scripts effectively allows arbitrary lua execution on the agent, and we&amp;rsquo;re not trying to build a botnet. If you own all of the agents in your natlas deployment, you could manually distribute your custom scripts to the agents and then enable it in the server.&lt;/p>
&lt;p>&lt;strong>Important:&lt;/strong> If you specify a script that doesn&amp;rsquo;t exist, all of your scan data will start to automatically fail. The agent currently doesn&amp;rsquo;t maintain a list of scripts it knows about, nor does it parse the error output when nmap fails to initialize.&lt;/p>
&lt;h3 id="screenshots">Screenshots&lt;/h3>
&lt;p>Natlas currently supports screenshotting two service types: HTTP and VNC.&lt;/p>
&lt;h4 id="http-screenshots">HTTP Screenshots&lt;/h4>
&lt;p>Natlas uses aquatone for web screenshots, which automatically reads the output of the nmap file using aquatone&amp;rsquo;s &lt;code>-nmap&lt;/code> flag. This means that it will attempt to screenshot hostnames if available, and IP addresses otherwise. Natlas currently does not support any custom flags for aquatone. It only supports a process timeout value, which can be used to keep your agents from lingering too long on any given task. If the timeout value is reached, the process will be killed and the output will not be processed.&lt;/p>
&lt;h4 id="vnc-screenshots">VNC Screenshots&lt;/h4>
&lt;p>Natlas currently uses vncsnapshot for vnc screenshots, and only on port 5900. A future version will support VNC on arbitrary ports and will hopefully provide more control over the screenshots you get to take. Like HTTP Screenshots, VNC screenshots also only support a process timeout value, after which the process will be killed and the output abandoned.&lt;/p></description></item><item><title>Docs: Host Coverage Strategy</title><link>/docs/concepts/host_coverage_strategy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/concepts/host_coverage_strategy/</guid><description>
&lt;p>The Natlas platform is a system capable of running either for long-term inventory scans with historical records or as a system intended for use as a search-head during an assessment. Natlas is intended for scanning any range scope - from a small local network up to the entire internet.&lt;/p>
&lt;p>Therefore scanning in Natlas has some operational requirements:&lt;/p>
&lt;ul>
&lt;li>It can not stress network bottlenecks
&lt;ul>
&lt;li>This can happen if scans for different targets share networking routes within short durations (e.g. anycast)&lt;/li>
&lt;li>Stability is critical for getting reliable and trustworthy results&lt;/li>
&lt;li>Avoids needlessly triggering alarms&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>It must avoid interrogation by monitoring strategies
&lt;ul>
&lt;li>Being detected by monitoring is typically Not-A-Big-Deal (TM), however nice to avoid&lt;/li>
&lt;li>It&amp;rsquo;s more important to have the scan targets be difficult to correlate
&lt;ul>
&lt;li>Difficult to infer scope and objectives of the campaign&lt;/li>
&lt;li>Difficult to relate scans to later stages&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Low resource cost on behalf of the scanner (e.g. CPU, memory)&lt;/li>
&lt;/ul>
&lt;p>For tools that are either long-running or are critical applications, other features may be desirable, for example:&lt;/p>
&lt;ul>
&lt;li>Provide a guarantee that coverage has been achieved&lt;/li>
&lt;li>Resumable/interruptible scans, or scans that can be migrated&lt;/li>
&lt;li>Scope that can be updated during runtime to meet pacing needs of the operating group&lt;/li>
&lt;/ul>
&lt;p>Because Natlas is used to provide comprehensive views of network inventory, guaranteeing coverage after a given amount of time is a high priority. It&amp;rsquo;s also useful to Natlas for scans to have a level of determinism - so that scans (including those deployed for large scopes) can be continued if the systems involved crash or are otherwise interrupted.&lt;/p>
&lt;h2 id="strategy">Strategy&lt;/h2>
&lt;p>To do this, the scanning engine performs randomized scans. Randomized scans avoid visiting clusters of similar target addresses (which could be anycast to the same systems, or otherwise rely on similar intermediary nodes and networking paths). This makes bursts of activity in any particular network route statistically unlikely by spreading out target traffic across the entire scope.&lt;/p>
&lt;p>Calling into an operating system provided source of randomness is a typical way to solve this problem. However, uniformly sampling scope ranges without storing state about previous scans and compensating for them makes it statistically improbable that &lt;strong>N&lt;/strong> randomly chosen network scans targeting &lt;strong>N&lt;/strong> addresses will result in full coverage. In fact, after one round of &lt;strong>N&lt;/strong> random samples only slightly more than half of endpoints are expected to have been scanned, and the scanner will have to scan about &lt;strong>12x-24x&lt;/strong> as many to expect to get full coverage (even then there are no guarantees, and the situation is worse for the larger ranges concerned in IPv6).&lt;/p>
&lt;p>Storing some kind of state to target new scans toward unreached endpoints seems inevitable. Unfortunately, storing full tables of scan state information for all endpoints is a formidable memory management problem for scans that grow larger than hundreds of thousands of endpoints (especially for full internet scans, or scans over IPv6 space). Traditional data-structures like bloom filters, cuckoo filters, and MRE caches have disadvantages that they speed up scan coverage without providing full coverage guarantees at the addititional cost of introducing false positives.&lt;/p>
&lt;p>Natlas uses a mathematical structure called a cyclic group to provide well distributed random numbers that also provably fully cover &lt;strong>N&lt;/strong> targets with &lt;strong>N&lt;/strong> sample scans. While generic versions of the algorithms involved with computing cyclic groups are complex and large sizes are used in modern cryptography, Natlas uses small cyclic groups whose computation is well within reasonable expected runtimes.&lt;/p>
&lt;h2 id="mathematical-background">Mathematical Background&lt;/h2>
&lt;p>There&amp;rsquo;s a large amount of background and terminology that this article will not go into (sorry number theorists!) out of respect for time.&lt;/p>
&lt;blockquote>
&lt;p>For number theorists - in short: Natlas uses a multiplicative cyclic group of prime order, and computes the factorization of the order of the group to obtain possible subgroup orders. Natlas uses these subgroup orders for generator testing, and finds random generators. Natlas uses these generators to determine the order of the scan. Mapping between group elements and IP addresses is performed by creating an index over IP addresses using canonical IP ordering.&lt;/p>
&lt;/blockquote>
&lt;p>Wikipedia describes Cyclic Groups as &amp;ldquo;In algebra, a cyclic group or monogenous group is a group that is generated by a single element.&amp;rdquo; This description is abstract but alludes the mathematical fact that we exploit for scanning in Natlas: an entire &amp;ldquo;group&amp;rdquo; (of IP addresses) can be generated by a small amount of state/information, and we&amp;rsquo;re guaranteed to generate every IP address in some order (we&amp;rsquo;ll later show how that order is pseudorandom).&lt;/p>
&lt;p>Let&amp;rsquo;s try out generating the &amp;ldquo;group of numbers 1-6&amp;rdquo; using the &amp;ldquo;single element 3&amp;rdquo;. We will multiply 3 by itself over and over, and take the remainder &lt;strong>mod 7&lt;/strong> (to keep the values between 1 and 6).&lt;/p>
&lt;p>3 mod 7 = &lt;strong>3&lt;/strong>&lt;/p>
&lt;p>3x3 mod 7 = &lt;strong>2&lt;/strong>&lt;/p>
&lt;p>3x3x3 mod 7 = &lt;strong>6&lt;/strong>&lt;/p>
&lt;p>3x3x3x3 mod 7 = &lt;strong>4&lt;/strong>&lt;/p>
&lt;p>3x3x3x3x3 mod 7 = &lt;strong>5&lt;/strong>&lt;/p>
&lt;p>3x3x3x3x3x3 mod 7 = &lt;strong>1&lt;/strong>&lt;/p>
&lt;p>By using &amp;ldquo;3&amp;rdquo; as a generator, we were able to obtain all numbers 1-6 in a random-looking order. It&amp;rsquo;s important that &amp;ldquo;mod 7&amp;rdquo; is using a prime number, or else this won&amp;rsquo;t work.&lt;/p>
&lt;blockquote>
&lt;p>Mathematicians have proven that every cyclic group that isn&amp;rsquo;t infinite in size, if the items in the &amp;ldquo;group&amp;rdquo; are relabeled, is equivalent to the numbers &lt;strong>mod n&lt;/strong> where &lt;strong>n&lt;/strong> is a prime number or a prime number raised to a power.&lt;/p>
&lt;/blockquote>
&lt;p>What Natlas will do is determine the total size of a scan scope, say 12345678 total IP addresses, and find the next prime number 12345701. Using calculations &amp;ldquo;mod 12345701&amp;rdquo;, we find a generator (the number 3 in the above example) and use it to list every number from 1-12345700 in a random-looking order. Natlas needs to throw away every number between 12345678 and 12345700, but there aren&amp;rsquo;t that many of them.&lt;/p>
&lt;p>There are important implementation details.&lt;/p>
&lt;h3 id="finding-a-generator">Finding a Generator&lt;/h3>
&lt;p>Not every number is a generator for a cyclic group. Take for example the proposed generator 2 with the group 1-6 from above:&lt;/p>
&lt;p>2 mod 7 = &lt;strong>2&lt;/strong>&lt;/p>
&lt;p>2x2 mod 7 = &lt;strong>4&lt;/strong>&lt;/p>
&lt;p>2x2x2 mod 7 = &lt;strong>1&lt;/strong>&lt;/p>
&lt;p>The next number generated (2x2x2x2 mod 7 = 2) is one that we&amp;rsquo;ve already visited. The reason for this is that 2 is a generator for a subgroup, and not the whole group. You may notice that the subgroup generated is exactly half as long as the whole group. That&amp;rsquo;s a good observation, and its true that all subgroups have a length that evenly divides the total size of the whole group.&lt;/p>
&lt;p>Natlas needs to find a true generator. To do this, it takes the prime number for the group, and subtracts one to get the number of values in (or &amp;ldquo;order of&amp;rdquo;) the group. As an example, &amp;ldquo;mod 7&amp;rdquo; has 6 elements. Then, the scanning engine factors this number to obtain all possible subgroup lengths. It randomly generates possible generators and tests them to see if they generate any subgroups. If a number is not a generator for any subgroup, it generates the whole group!&lt;/p>
&lt;p>The number of generators for a given group can be counted using a complex formula (involving the number of relatively prime numbers to other numbers). Needless to say, there are always a &amp;ldquo;lot&amp;rdquo; of generators, and this method of generation will quickly find one.&lt;/p>
&lt;p>Our scanning engine chooses a random generator every restart, and picks a random location in that generator&amp;rsquo;s cycle to start scanning from. This increases the uniform pseudorandom nature of the scanning strategy.&lt;/p>
&lt;h3 id="computing-modular-exponentiation-quickly">Computing Modular Exponentiation Quickly&lt;/h3>
&lt;p>The scanning engine uses an algorithm capable of quickly calculating exponents, and keeps the numbers small by keeping all intermediate values modulo the group order.&lt;/p>
&lt;p>Essentially, 3x3x3x3x3 mod 7 doesn&amp;rsquo;t need to be explicitly calculated from scratch if 3x3x3x3 mod 7 already has. Just multiply the second number by the 3 to obtain the first.&lt;/p>
&lt;p>Calculating arbitrarily large exponents of arbitrary generators can be done by repeatedly squaring an intermediate value, and multiplying that value into a final calculation if it contributes.&lt;/p>
&lt;p>Wikipedia hosts a well-written article on the details of &lt;a href="https://en.wikipedia.org/wiki/Exponentiation_by_squaring">Exponentiation by squaring&lt;/a>&lt;/p>
&lt;h3 id="indexing-ip-addresses">Indexing IP Addresses&lt;/h3>
&lt;p>When all of the elements of the group can be generated, we need to be able to translate them back into IP addresses. To do this, we put IP network blocks into a random access array in canonical address order (e.g. 1.1.1.1 &amp;lt; 192.168.0.1). One time at the start of any scan configuration, the scanning engine walks the address blocks and counts the total number of IP addresses accumulated up until each networking block.&lt;/p>
&lt;p>With an index, binary search can then be used to determine which network address range is associated, and within that range, which IP address is mapped. It&amp;rsquo;s important to note that changing the scope of a scan causes all of the addresses to be reindexed.&lt;/p>
&lt;h3 id="but-factoring-and-discrete-log-are-hard">But Factoring and Discrete Log Are Hard&lt;/h3>
&lt;p>Yes and No!&lt;/p>
&lt;p>Natlas&amp;rsquo;s generator has some properties which make it similar to provably secure pseudorandom number generators (e.g. Blum Blum Shub), but the numbers involved - 32 bits for IPv4 128 bits for IPv6 - are small enough that these calculations can be done rather simply. Performance has been tested on the full 32 bit range and into the 64 bit ranges without any obvious performance issues.&lt;/p>
&lt;h3 id="the-average-time-delta-is-too-variable">The Average Time Delta is Too Variable&lt;/h3>
&lt;p>If you&amp;rsquo;re trying to get consistent scan cycles, it may be valuable to not generate a new random order for every cycle. The random order tends to mean that sometimes a host is scanned a couple minutes apart and other times a couple days apart, which isn&amp;rsquo;t necessarily ideal. To this end, Natlas introduced a &lt;code>CONSISTENT_SCAN_CYCLE&lt;/code> option that can be set, which will reuse the same random order as long as the scope hasn&amp;rsquo;t changed, resulting in more consistent timing between scans of a given host.&lt;/p>
&lt;h2 id="show-me-the-code">Show me the code&lt;/h2>
&lt;p>The &lt;a href="https://github.com/natlas/cyclicprng">cyclic PRNG&lt;/a> has been separated out from the Natlas platform to a standalone package that can be installed via pip. You can checkout the code yourself or jump right in by running &lt;code>pipenv install cyclicprng&lt;/code>.&lt;/p>
&lt;p>Initialization of the PRNG is quick, even for address spaces up to 2^128 (the entire IPv6 address space) - typically less than a tenth of a second on a modern computer.&lt;/p>
&lt;p>The process by which these cyclical random numbers are turned into an IP address to scan has not been separated from the Natlas server at this time, however the logic is pretty well consolidated into &lt;a href="https://github.com/natlas/natlas/blob/main/natlas-server/app/scope/scan_manager.py">the scan manager&lt;/a>.&lt;/p></description></item><item><title>Docs: Port Coverage Strategies</title><link>/docs/concepts/port_coverage_strategies/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/concepts/port_coverage_strategies/</guid><description>
&lt;h2 id="current-strategy">Current Strategy&lt;/h2>
&lt;p>Currently, we have only one port coverage strategy - Define ports to be given to the natlas-agent via the natlas-services file. This feeds directly to nmap and we scan all the ports in the natlas-services file. This has the advantage of being simple while also allowing per-deployment customization of what ports to scan. But it has the disadvantage of not scaling up very well; you could add another 5000 ports but nmap is not a very fast scanner by default. So basically you don&amp;rsquo;t identify anything &lt;em>new&lt;/em> with this approach, only the things that you think you might find ahead of time.&lt;/p>
&lt;h2 id="proposals">Proposals&lt;/h2>
&lt;p>Ideally we&amp;rsquo;d like to have all of these capabilities to allow for flexibility in configuration, as each has it&amp;rsquo;s own drawbacks and advantages.&lt;/p>
&lt;h3 id="the-multi-armed-bandit">The Multi Armed Bandit&lt;/h3>
&lt;p>It would be possible to design scanning behavior that models the scarceness of scanning resources and optimizes its use, given a given scanning scope. Since every scan costs CPU and networking resources as well as latency, and any scan on any port has some statistical chance at reward that depends on the port, Natlas could model the scanning problem as an instance of the well studied &lt;a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-Armed Bandit problem&lt;/a> for which optimal and rapidly converging strategies are known.&lt;/p>
&lt;p>Effectively, when it is time to scan a particular host - or set of hosts - the Natlas server would utilize information it has previously collected to fine tune its scanning ranges. In a &amp;ldquo;vanilla&amp;rdquo; multi-armed bandit model, the decision of the server to scan hosts on specific ports would only include information about which ports have been seen before as statistical aggregates across the entire scope. However, if a variations of the problem - such as &amp;ldquo;contextual bandits&amp;rdquo; - were used as the model, it would be possible to combine scope tags, ASNs, and/or other information with port statistics to narrow in on favorable port scan targets.&lt;/p>
&lt;p>The resulting experience would be that a Natlas administrator would set a certain number of ports each agent would be expected to scan, but not specify which ports these should be or could optionally provide &amp;ldquo;seed ports&amp;rdquo; that are initial exposure guesses to start the scan off with. Natlas would then - over the course of several scanning Epochs - use scan results it is collecting as feedback to refine what ports it is asking the agents to scan. Effectively, over time, this would result in scanning the most common ports in &lt;em>that specific&lt;/em> scope, without needing to scan all 65k ports on all hosts all the time.&lt;/p>
&lt;p>The algorithms that solve this problem always allocate a few resources for &amp;ldquo;exporation&amp;rdquo;, which means that even after a large number of scanning epochs has passed, new scans will balance the risk of scanning ports not likely to result in discoveries against the need to determine probe unlikely ports to learn whether historically collected statistics are still accurate.&lt;/p>
&lt;p>&lt;strong>Pros:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Results in an efficient use of scans&lt;/li>
&lt;li>Works in scenarios where few common ports are active, and they may not be known in advance&lt;/li>
&lt;li>Can be tuned to be more aggressive or conservative and to learn faster or slower&lt;/li>
&lt;li>Can start out identical to default port lists (e.g. nmap)&lt;/li>
&lt;li>Can be combined with other approaches so that there are a &amp;ldquo;must have&amp;rdquo; port scan, and remaining ports are &amp;ldquo;learned&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Cons:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Can not guarantee that specific hosts/port combinations will be scanned&lt;/li>
&lt;li>Host history will not be garunteed to be an apples-to-apples comparison&lt;/li>
&lt;li>This introduces state into the server portion of Natlas&lt;/li>
&lt;li>The architecture would need to be redesigned to support dynamic per-scan port and service targets&lt;/li>
&lt;li>Bugs in scanning logic or deployment will result in artifacts that get &amp;ldquo;learned&amp;rdquo;. For example, if the scanner loses all packets inbound from the target scope, the strategy will learn that all ports are equally as good (since scan results indicate that all ports are down for all hosts)&lt;/li>
&lt;/ul>
&lt;h3 id="pre-flight-masscan">Pre-flight Masscan&lt;/h3>
&lt;p>This is a simple proposal for an agent to run masscan for all ports against each host before passing the open ports to nmap for deeper scanning. At a rate limit of 10000pps, this would add approximately 65 seconds per agent job. It would take some time out of the nmap scanning phase, because nmap would receive a list of ports that should be open, so it shouldn&amp;rsquo;t be spending much time scanning ports that aren&amp;rsquo;t open. It would also have the benefit of not relying on nmap&amp;rsquo;s host discovery, which can often be tricked into reporting a host as down. The option currently exists to tell nmap to skip it&amp;rsquo;s host discovery phase (&lt;code>-Pn&lt;/code>), but this is also slow because it means it checks every port no matter what. It is quite common across recon enthusiasts to use masscan prior to nmap, though the typical model for masscan is a port-oriented strategy which scans large ranges of network space for a limited number of ports, rather than what we&amp;rsquo;re doing here.&lt;/p></description></item><item><title>Docs: Scope Ingestion Strategies</title><link>/docs/concepts/scope_ingestion_strategies/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/concepts/scope_ingestion_strategies/</guid><description>
&lt;h2 id="current-strategy">Current Strategy&lt;/h2>
&lt;p>Currently, Natlas only supports manually imported scope in the form of CIDR ranges. This may work well for scans of RFC1918 address space, as well as for larger organizations that have static CIDR ranges on the internet. But it really doesn&amp;rsquo;t work well for smaller organizations using cobbled together address space, let alone cloud-native companies.&lt;/p>
&lt;h2 id="possible-strategies">Possible Strategies&lt;/h2>
&lt;ul>
&lt;li>(Priority) DNS enumeration ingestion
&lt;ul>
&lt;li>Given one or more apex domains, perform subdomain enumeration and use valid subdomains to populate scope.&lt;/li>
&lt;li>Requires the ability to:
&lt;ol>
&lt;li>Automatically add ip addresses of new subdomains to scanning&lt;/li>
&lt;li>Add new subdomains to a review queue where an administrator decides to scan or not&lt;/li>
&lt;li>Blacklist DNS names such that no matter what ip they point to, we do not scan them&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>Can be automated fairly well with the use of amass for enumeration and background workers that regularly re-resolve already known records (and keep a history of these re-resolves)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Authenticated DNS zone transfer ingestion
&lt;ul>
&lt;li>If you are an administrator or on the IT team for an organization, you may wish to perform authenticated zone transfers in order to maintain an authoritative source of DNS records to scan for&lt;/li>
&lt;li>Likely a relatively low priority option, and could be easily automated with a Natlas API and a curl script in the meantime&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Cloud Provider Events API(s)
&lt;ul>
&lt;li>Receive / subscribe to events for your cloud provider in order to receive notification of new hosts being deployed and then automatically feed these into natlas scope&lt;/li>
&lt;li>Works really well for scanning primarily cloud environments&lt;/li>
&lt;li>Likely requires plugins for GCP, AWS, Azure, etc&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Cloud Provider Enumeration API(s)
&lt;ul>
&lt;li>Periodically (on a configurable time) run tooling that queries cloud provider APIs to build a list of hosts to be ingested for scanning&lt;/li>
&lt;li>Can create a minor gap in receiving information about new hosts when compared to the previous events api source&lt;/li>
&lt;li>Similarly will require plugins for GCP, AWS, Azure, etc&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="scope-ingestion-methods">Scope Ingestion Methods&lt;/h2>
&lt;ul>
&lt;li>Add or remove a single item from scope/blacklist&lt;/li>
&lt;li>Add or remove a batch of items from scope/blacklist&lt;/li>
&lt;li>Replace the entire scope/blacklist for a given ingestion source
&lt;ul>
&lt;li>We don&amp;rsquo;t want DNS zone transfer updates to be additive, for instance. We know these will be the hosts to scan and will likely want to completely invalidate the previous scope, opposed to diffing the previous scope and the new scope and then removing/adding as necessary. Functionally they would result in the same thing, and in probably very comparable performance.&lt;/li>
&lt;li>Note the addition of &amp;ldquo;ingestion source&amp;rdquo;, which indicates that if we allow automated ingestion, we will need to include an ingestion source so that things don&amp;rsquo;t necessarily overwrite one another.&lt;/li>
&lt;li>This is basically just &amp;ldquo;Add or remove a batch of items&amp;rdquo; run back to back, first removing and then adding, based on a query for the ingestion source.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Remove the entire scope/blacklist for a given ingestion source
&lt;ul>
&lt;li>Similar to replace, create a query for scope from a given ingestion source and then batch remove those items.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="caveats">Caveats&lt;/h2>
&lt;p>Automating scope ingestion too frequently will wreak havoc on the PRNG, preventing us from reliably reaching full scope coverage, which was the whole point of the PRNG in the first place. This means we need to discuss mechanisms for new scope to be added without interrupting the existing PRNG cycle, but without necessarily waiting until it&amp;rsquo;s completely finished before we start scanning the new scope. One option for this is that changes to the scope go into a second scan manager, or a scan manager cache of sorts, and then jobs are distributed from between them. The problem is that this may grow out of hand if scope ingestion is happening too frequently, unless the scan manager says &amp;ldquo;Okay those are in my current scope so I&amp;rsquo;m not going to cache them, but these other ones are new so we&amp;rsquo;ll add them to our secondary job queue&amp;rdquo;. Anyways, this is just something to think about as we move towards implementing this.&lt;/p></description></item><item><title>Docs: Security Considerations</title><link>/docs/concepts/security-considerations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/concepts/security-considerations/</guid><description>
&lt;p>A security tool, if you can call Natlas that, wouldn&amp;rsquo;t be very good if it introduces more vulnerabilities than it identifies. As such, we keep security in mind through every step of development. We&amp;rsquo;ll talk about the way we use containers, the boundaries between the server and the agent, and how to develop new features.&lt;/p>
&lt;h2 id="secure-by-default">Secure By Default&lt;/h2>
&lt;p>As can be seen from many other open source projects, if a project is provided that doesn&amp;rsquo;t enable security out of the box, then there&amp;rsquo;s a very good chance that security will never get enabled. Natlas is building a map of all the interesting things in your network, so it makes sense that you might want to ensure that only authorized people can look at it. That&amp;rsquo;s why Natlas ships with both user and agent authentication required, as well as separation between admin users and regular users. We believe that security shouldn&amp;rsquo;t be an expansion to the project, nor should it be opt-in.&lt;/p>
&lt;h2 id="natlas-containers">Natlas Containers&lt;/h2>
&lt;p>Natlas uses containers for both the agent and the server. Containers by themselves shouldn&amp;rsquo;t be inherently considered a security boundary, but we can use them to at least ensure that we aren&amp;rsquo;t running with more privileges than we need.&lt;/p>
&lt;h3 id="server-container">Server Container&lt;/h3>
&lt;p>The server container does launch as root, technically. This is so that it can create directories in the persistent storage that it requires and make sure that it can write to those files. Through normal operation, the entrypoint of the container will make sure the files it needs exists, make sure the database is up to date, and then run the server as the &lt;code>www-data&lt;/code> user. This entrypoint script may be removed in the future and it&amp;rsquo;ll be the user&amp;rsquo;s responsibility to ensure that the app can write to the persistent storage mount.&lt;/p>
&lt;p>We also make an effort to provide slim containers, however the application requires the python interpreter to run, so if it were compromised then the python interpreter would be available to do anything an attacker might want.&lt;/p>
&lt;h3 id="agent-container">Agent Container&lt;/h3>
&lt;p>The agent container launches exclusively as the &lt;code>www-data&lt;/code> user. The agent uses nmap and aquatone, we have to provide some specific flags in order to function correctly. &lt;code>Nmap&lt;/code> runs with the &lt;code>--privileged&lt;/code> flag, which lets us do SYN scans without needing to be root, but requires &lt;code>CAP_NET_ADMIN&lt;/code> when the container is launched (&lt;code>--cap-add=NET_ADMIN&lt;/code>). Since aquatone relies on chromium, we have to consider how to launch chromium from within docker. Many searches on this topic will tell users &amp;ldquo;oh just run with &amp;ndash;no-sandbox&amp;rdquo; but we&amp;rsquo;d like to be a little less reckless than that. Thankfully, &lt;a href="https://github.com/jessfraz">Jess Frazelle&lt;/a> has gone to a lot of effort to dockerize all sorts of applications, including Chrome. Natlas makes use of Jess&amp;rsquo; &lt;a href="https://github.com/jessfraz/dotfiles/blob/master/etc/docker/seccomp/chrome.json">seccomp profile&lt;/a> for Chrome, which allows us to run chrome in our container as expected.&lt;/p>
&lt;h2 id="server-agent-boundary">Server-Agent Boundary&lt;/h2>
&lt;p>One might look at a distribution platform like this and think &amp;ldquo;oh yeah, if we just compromise the server then we can compromise all of the agents.&amp;rdquo; With this in mind, we try to ensure that even if the server is compromised or otherwise wants to act maliciously, the agents can protect themselves. This means they don&amp;rsquo;t take arbitrary commands from the server, but rather they only take supported commands that it can map. The agent also never runs subprocesses with &lt;code>SHELL=True&lt;/code>, which prevents shell expansion attacks and command injection attacks. The only user controlled values that go to the subprocesses are the target IP address, which must be a valid IP address to be put into the server and must be a valid IP address when the agent receives it, otherwise the agent will reject it.&lt;/p>
&lt;p>Another possibile activity to consider with a compromised server is the ability to map inside the agents&amp;rsquo; local networks. Agents could be located anywhere and run by anyone, especially in a community or group oriented deployment. As such, they ship with an option called &lt;code>NATLAS_SCAN_LOCAL&lt;/code> set to False. This will automatically reject any targets that are considered &lt;a href="https://tools.ietf.org/html/rfc1918">RFC1918&lt;/a> addresses (colloquially called 1918 addresses), thereby preventing a malicious server from enumerating the inside of the agent&amp;rsquo;s network. Of course, you might &lt;em>want&lt;/em> to scan local addresses, such as when you&amp;rsquo;re scanning your organization&amp;rsquo;s &lt;code>10.0.0.0/8&lt;/code> or similar. To support this, simply toggle &lt;code>NATLAS_SCAN_LOCAL=True&lt;/code> for each of your agents.&lt;/p>
&lt;p>There may be a future version of Natlas that worries less about this boundary, which would allow easier implementation of features such as issuing raw nmap commands or automatically distributing custom scripts. This would be ideal for single-tenant deployments where all agents are controlled by the same user. This is currently not on the roadmap, however.&lt;/p></description></item><item><title>Docs: NGINX as a Reverse Proxy</title><link>/docs/configuration/nginx-as-a-reverse-proxy/</link><pubDate>Fri, 14 Aug 2020 00:00:00 +0000</pubDate><guid>/docs/configuration/nginx-as-a-reverse-proxy/</guid><description>
&lt;div class="pageinfo pageinfo-primary">
&lt;p>This section provides resources for setting up nginx as a reverse proxy for your Natlas server.&lt;/p>
&lt;/div>
&lt;p>It is not really advisable to run the flask application directly on the internet (or even on your local network). The flask application is just that, an application. It doesn&amp;rsquo;t account for things like SSL certificates, and modifying application logic to add in potential routes for things like Let&amp;rsquo;s Encrypt should be avoided. Luckily, it&amp;rsquo;s very easy to setup a reverse proxy so that all of this stuff can be handled by a proper web server and leave your application to do exactly what it&amp;rsquo;s supposed to do.&lt;/p>
&lt;p>We provide an example nginx configuration file, however you should familiarize yourself with how to use and secure nginx.&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-open-source/">Installing Nginx&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy/">Nginx Reverse Proxy&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://certbot.eff.org/lets-encrypt/ubuntufocal-nginx">Using Certbot with Nginx&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.nginx.com/nginx/admin-guide/security-controls/">Nginx Security Controls&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://ssl-config.mozilla.org/">Mozilla SSL Configuration Generator&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>You can grab our example config to help get started:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">sudo curl https://raw.githubusercontent.com/natlas/natlas/main/natlas-server/deployment/nginx &amp;gt; /etc/nginx/sites-available/natlas
&lt;/code>&lt;/pre>&lt;/div></description></item></channel></rss>